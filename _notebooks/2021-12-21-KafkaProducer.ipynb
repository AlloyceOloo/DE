{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efc8445",
   "metadata": {},
   "source": [
    "# Producing scraped data to a Kafka Topic in Python\n",
    "\n",
    "> A simple tutorial demonstrating how to send data to a Kafka topic using KafkaProducer in python\n",
    "\n",
    "- title: \"Web Scraping with Apache Kafka\"\n",
    "- toc: true\n",
    "- branch: master\n",
    "- comments: true\n",
    "- categories: [fastpages, jupyter]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841592b",
   "metadata": {},
   "source": [
    "## Install the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aef580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from kafka import KafkaProducer\n",
    "import time\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import json\n",
    "from json import loads\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76882e",
   "metadata": {},
   "source": [
    "## Create the Kafka Topic to produce data to\n",
    "\n",
    "#kafka code for setting up a local kafka server\n",
    "\n",
    "#run in terminal\n",
    "\n",
    "\n",
    "bin/zookeeper-server-start.sh config/zookeeper.properties\n",
    "\n",
    "\n",
    "bin/kafka-server-start.sh config/server.properties\n",
    "\n",
    "\n",
    "bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic scrapeTut10 --partitions 1 --replication-factor 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465f31f4",
   "metadata": {},
   "source": [
    "## Declare the necessary variables for storing the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_desc = []\n",
    "property_price = []\n",
    "property_location = []\n",
    "property_beds = []\n",
    "property_baths = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d80e5",
   "metadata": {},
   "source": [
    "## Create an instance of the Mongo DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_client = MongoClient()\n",
    "db = my_client.scrapeCollection\n",
    "posts = db.posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52084c2",
   "metadata": {},
   "source": [
    "## Create a Kafka producer to run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493fd560",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_producer3 = KafkaProducer(\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    value_serializer = lambda x:dumps(x).encode('utf-8')  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed291fea",
   "metadata": {},
   "source": [
    "## Define the url for scraping and loop through the web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1faf436",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1,2):\n",
    "\n",
    "    url = 'https://www.property24.co.ke/1-bedroom-properties-to-rent-in-nairobi-p95?Bathrooms=1&PropertyTypes=houses%2capartments-flats%2ctownhouses&Page=' + str(page)\n",
    "    html_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "    properties = soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a5696",
   "metadata": {},
   "source": [
    "## For each property, define and store the relevant attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a537f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for properties in properties:\n",
    "\n",
    "        property_desc = properties.find('div', class_='sc_listingTileArea').text.replace('\\r','').replace('\\n','')\n",
    "        property_price = properties.find('span').text.replace(' ','').replace('KSh','').replace('\\r','').replace('\\n','')\n",
    "        property_location = properties.find('div', class_='sc_listingTileAddress primaryColor').text.replace('\\r','').replace('\\n','').replace(' ','')\n",
    "        property_beds = properties.find('div', class_='sc_listingTileIcons').text.split()[0].replace(' ','')\n",
    "        property_baths = properties.find('div', class_='sc_listingTileIcons').text.split()[1].replace(' ','')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec1b249",
   "metadata": {},
   "source": [
    "## Define a dictionary and convert it to a dataframe and a json object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {\n",
    "    'Property Title':[property_desc],\n",
    "    'Property Price':[property_price],\n",
    "    'Property Location':[property_location],\n",
    "    'Property Bedrooms':[property_beds],\n",
    "    'Property Bathrooms':[property_baths]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data2)\n",
    "\n",
    "df['Property Price'] = df['Property Price'].astype(float)\n",
    "df['Property Bedrooms'] = df['Property Bedrooms'].astype(float)\n",
    "df['Property Bathrooms'] = df['Property Bathrooms'].astype(float)\n",
    "\n",
    "#json object, kafka can't recieve dataframes\n",
    "result = df.to_json(orient=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7af1f",
   "metadata": {},
   "source": [
    "## Send the json object to Kafka, and the dictionary to Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_producer3.send('scrapeTut10', value=result)\n",
    "\n",
    "posts.insert_one(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68cd8b",
   "metadata": {},
   "source": [
    "## Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0850dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    import lxml\n",
    "    from bs4 import BeautifulSoup\n",
    "    from time import sleep\n",
    "    from kafka import KafkaProducer\n",
    "    import time\n",
    "    from time import sleep\n",
    "    import numpy as np\n",
    "    import json\n",
    "    from json import loads\n",
    "    from json import dumps\n",
    "    from kafka import KafkaProducer\n",
    "    from pymongo import MongoClient\n",
    "    \n",
    "\n",
    "    #initialize the variables to store property information\n",
    "    property_desc = []\n",
    "    property_price = []\n",
    "    property_location = []\n",
    "    property_beds = []\n",
    "    property_baths = []\n",
    "\n",
    "    #initialize the mongo database connection\n",
    "    try:        \n",
    "        my_client = MongoClient()\n",
    "        db = my_client.scrapeCollection\n",
    "        posts = db.posts\n",
    "    except Exception as e:\n",
    "        print(\"Mongo DB Error\")\n",
    "\n",
    "    #running kafka locally\n",
    "    try:\n",
    "        my_producer3 = KafkaProducer(\n",
    "            bootstrap_servers=['localhost:9092'],\n",
    "            value_serializer = lambda x:dumps(x).encode('utf-8')  \n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Kafka Error\")\n",
    "    \n",
    "    #scrape the first page of the website only\n",
    "    for page in range(1,2):\n",
    "        \n",
    "        try:            \n",
    "            url = 'https://www.property24.co.ke/1-bedroom-properties-to-rent-in-nairobi-p95?Bathrooms=1&PropertyTypes=houses%2capartments-flats%2ctownhouses&Page=' + str(page)\n",
    "            html_text = requests.get(url).text\n",
    "            soup = BeautifulSoup(html_text, 'lxml')\n",
    "            properties = soup.find_all('div', class_='pull-left sc_listingTileContent')\n",
    "        except Exception as e:\n",
    "            print(\"URL error\")\n",
    "            \n",
    "        for properties in properties:\n",
    "\n",
    "            property_desc = properties.find('div', class_='sc_listingTileArea').text.replace('\\r','').replace('\\n','')\n",
    "            property_price = properties.find('span').text.replace(' ','').replace('KSh','').replace('\\r','').replace('\\n','')\n",
    "            property_location = properties.find('div', class_='sc_listingTileAddress primaryColor').text.replace('\\r','').replace('\\n','').replace(' ','')\n",
    "            property_beds = properties.find('div', class_='sc_listingTileIcons').text.split()[0].replace(' ','')\n",
    "            property_baths = properties.find('div', class_='sc_listingTileIcons').text.split()[1].replace(' ','')\n",
    "\n",
    "            print(f\"\"\"\n",
    "            Property Title: {property_desc}\n",
    "            Property Price: {property_price}\n",
    "            Property Location: {property_location}\n",
    "            Property Bedrooms: {property_beds}\n",
    "            Property Bathrooms: {property_baths}\n",
    "\n",
    "            \"\"\")\n",
    "\n",
    "            print('')\n",
    "\n",
    "            data2 = {\n",
    "                'Property Title':[property_desc],\n",
    "                'Property Price':[property_price],\n",
    "                'Property Location':[property_location],\n",
    "                'Property Bedrooms':[property_beds],\n",
    "                'Property Bathrooms':[property_baths]\n",
    "            }\n",
    "\n",
    "            df = pd.DataFrame(data2)\n",
    "            \n",
    "            df['Property Price'] = df['Property Price'].astype(float)\n",
    "            df['Property Bedrooms'] = df['Property Bedrooms'].astype(float)\n",
    "            df['Property Bathrooms'] = df['Property Bathrooms'].astype(float)\n",
    "            \n",
    "            #json object, kafka can't recieve dataframes\n",
    "            result = df.to_json(orient=None)\n",
    "            \n",
    "            #scrapeTut10 is the kafka topic in use\n",
    "            try:                \n",
    "                my_producer3.send('scrapeTut10', value=result)\n",
    "            except Exception as e:\n",
    "                print(\"Kafka Topic Error\")\n",
    "            \n",
    "            #mongodb used as a data lake\n",
    "            try:\n",
    "                posts.insert_one(data2)\n",
    "            except Exception as e:\n",
    "                print(\"MongoDB keyspace error\")\n",
    "            #timer to avoid getting blocked from the website\n",
    "            time_wait = 5\n",
    "            time.sleep(time_wait * 1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b9f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
